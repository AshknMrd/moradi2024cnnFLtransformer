{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset.json file is required in the transformaer-based experiment: \n",
    "\n",
    "\n",
    "# CT data experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ----------------------------\n",
    "# Define paths\n",
    "# ----------------------------\n",
    "base_dir = \"./ct_dataset\"\n",
    "images_tr_dir = os.path.join(base_dir, \"imagesTr\")\n",
    "labels_tr_dir = os.path.join(base_dir, \"labelsTr\")\n",
    "images_ts_dir = os.path.join(base_dir, \"imagesTs\")\n",
    "labels_ts_dir = os.path.join(base_dir, \"labelsTs\")\n",
    "\n",
    "# ----------------------------\n",
    "# Helper function to match images and labels\n",
    "# ----------------------------\n",
    "def create_file_pairs(images_dir, labels_dir):\n",
    "    images = sorted([f for f in os.listdir(images_dir) if f.endswith(\".nii.gz\")])\n",
    "    labels = sorted([f for f in os.listdir(labels_dir) if f.endswith(\".nii.gz\")])\n",
    "    return [\n",
    "        {\"image\": os.path.join(images_dir, img), \"label\": os.path.join(labels_dir, img)}\n",
    "        for img in images if img in labels\n",
    "    ]\n",
    "\n",
    "# ----------------------------\n",
    "# Prepare training and validation data\n",
    "# ----------------------------\n",
    "data_list_tr = create_file_pairs(images_tr_dir, labels_tr_dir)\n",
    "train_data, val_data = train_test_split(data_list_tr, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----------------------------\n",
    "# Prepare test data\n",
    "# ----------------------------\n",
    "data_list_ts = create_file_pairs(images_ts_dir, labels_ts_dir)\n",
    "\n",
    "# ----------------------------\n",
    "# Create dataset dictionary\n",
    "# ----------------------------\n",
    "dataset_json = {\n",
    "    \"name\": \"Amos22_CT_Dataset\",\n",
    "    \"description\": \"CT-Dataset ...\",\n",
    "    \"tensorImageSize\": \"4D\",\n",
    "    \"modality\": {\"0\": \"CT\"},\n",
    "    \"labels\": {\"0\": \"background\", \"1\": \"organ\"},\n",
    "    \"numTraining\": len(train_data),\n",
    "    \"numValidation\": len(val_data),\n",
    "    \"numTest\": len(data_list_ts),\n",
    "    \"training\": train_data,\n",
    "    \"validation\": val_data,\n",
    "    \"test\": data_list_ts,\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Save JSON\n",
    "# ----------------------------\n",
    "output_json_path = os.path.join(base_dir, \"dataset_split.json\")\n",
    "with open(output_json_path, \"w\") as f:\n",
    "    json.dump(dataset_json, f, indent=4)\n",
    "\n",
    "print(f\"Dataset JSON saved at {output_json_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PI-CAI bpMRI experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ----------------------------\n",
    "# Dataset directories\n",
    "# ----------------------------\n",
    "data_dir = \"./workdir/nnUNet_raw/Dataset104_picai\"\n",
    "images_dir = os.path.join(data_dir, \"imagesTr\")\n",
    "labels_dir = os.path.join(data_dir, \"labelsTr\")\n",
    "\n",
    "# ----------------------------\n",
    "# List and process cases\n",
    "# ----------------------------\n",
    "cases = sorted(\n",
    "    f[:-9]  # remove \"_0000.nii.gz\"\n",
    "    for f in os.listdir(images_dir)\n",
    "    if f.endswith(\"_0000.nii.gz\")\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Split into training and validation (80/20)\n",
    "# ----------------------------\n",
    "train_cases, val_cases = train_test_split(cases, test_size=0.2, random_state=42)\n",
    "train_cases, val_cases = sorted(train_cases), sorted(val_cases)\n",
    "\n",
    "# ----------------------------\n",
    "# Modality suffix map\n",
    "# ----------------------------\n",
    "suffix_map = {\"T2W\": \"_0000\", \"ADC\": \"_0001\", \"HBV\": \"_0002\"}\n",
    "\n",
    "# ----------------------------\n",
    "# Build dataset JSON structure\n",
    "# ----------------------------\n",
    "def build_dataset_entry(cases_list):\n",
    "    return [\n",
    "        {\n",
    "            \"image\": [os.path.join(images_dir, f\"{case}{suffix_map[mod]}.nii.gz\") for mod in [\"T2W\", \"ADC\", \"HBV\"]],\n",
    "            \"label\": os.path.join(labels_dir, f\"{case}.nii.gz\")\n",
    "        }\n",
    "        for case in cases_list\n",
    "    ]\n",
    "\n",
    "dataset_dict = {\n",
    "    \"channel_names\": { \"0\": \"T2W\", \"1\": \"ADC\", \"2\": \"HBV\" },\n",
    "    \"labels\": { \"background\": 0, \"lesion\": 1 },\n",
    "    \"numTraining\": len(train_cases),\n",
    "    \"file_ending\": \".nii.gz\",\n",
    "    \"name\": \"picai_nnunetv2\",\n",
    "    \"reference\": \"none\",\n",
    "    \"release\": \"1.0\",\n",
    "    \"description\": \"bpMRI scans from PI-CAI dataset to train by nnUNetv2\",\n",
    "    \"overwrite_image_reader_writer\": \"SimpleITKIO\",\n",
    "    \"training\": build_dataset_entry(train_cases),\n",
    "    \"validation\": build_dataset_entry(val_cases)\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Save JSON file\n",
    "# ----------------------------\n",
    "output_path = os.path.join(data_dir, \"dataset.json\")\n",
    "with open(output_path, \"w\") as json_file:\n",
    "    json.dump(dataset_dict, json_file, indent=4)\n",
    "\n",
    "print(f\"Dataset JSON saved: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
