{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a Transformer on PI-CAI Dataset for csPCa detection:\n",
    "\n",
    "## Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import monai\n",
    "from monai.losses import FocalLoss\n",
    "from monai.transforms import (    \n",
    "    AsDiscrete,EnsureChannelFirstd,Compose,LoadImaged,\n",
    "    Orientationd,SpatialPadd, CenterSpatialCropd,Spacingd,ScaleIntensityRangePercentilesd)\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR\n",
    "from monai.data import DataLoader,Dataset,load_decathlon_datalist,decollate_batch\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "root_dir = \"./results_output_picai\"\n",
    "datasets_json = \"./workdir/dataset_picai.json\"\n",
    "\n",
    "num_train = 25\n",
    "num_val = 5\n",
    "max_iterations = 10 \n",
    "eval_num = 5 \n",
    "\n",
    "train_transforms_simple = Compose(\n",
    "    [LoadImaged(keys=[\"image\", \"label\"]),\n",
    "     EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "     Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "     Spacingd(keys=[\"image\", \"label\"],pixdim=(0.5, 0.5, 3.0),mode=(\"bilinear\", \"nearest\"),),\n",
    "     SpatialPadd(keys=[\"image\", \"label\"], spatial_size=(272, 272, 32)), \n",
    "     ScaleIntensityRangePercentilesd(keys=[\"image\"], lower=1, upper=99, b_min=0.0, b_max=1.0, clip=True),])\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [LoadImaged(keys=[\"image\", \"label\"]),\n",
    "     EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "     Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "     Spacingd(keys=[\"image\", \"label\"],pixdim=(0.5, 0.5, 3.0),mode=(\"bilinear\", \"nearest\"),),\n",
    "     SpatialPadd(keys=[\"image\", \"label\"], spatial_size=(272, 272, 32)), \n",
    "     CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=(272, 272, 32)), \n",
    "     ScaleIntensityRangePercentilesd(keys=[\"image\"], lower=1, upper=99, b_min=0.0, b_max=1.0, clip=True),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = load_decathlon_datalist(datasets_json, True, \"training\")[:num_train]\n",
    "val_files = load_decathlon_datalist(datasets_json, True, \"validation\")[:num_val]\n",
    "\n",
    "train_ds = Dataset(data=datalist,transform=train_transforms_simple,)\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNETR(\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    img_size=(272, 272, 32),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    proj_type=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.3,\n",
    ").to(device)\n",
    "\n",
    "post_label = AsDiscrete(to_onehot=2)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=2)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function and the optimizer: \n",
    "\n",
    "Depending on the task in hand the Loss function is selected Focal loss, CE loss, or Dice CE loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = monai.losses.DiceCELoss(include_background=False, to_onehot_y=True, softmax=True)\n",
    "loss_function = FocalLoss(to_onehot_y=True, gamma=2.0)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "for global_step in range(max_iterations):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    print(f\"Global training step: {global_step}/{max_iterations}\")\n",
    "\n",
    "    for step, batch in enumerate(train_loader, start=1):\n",
    "        x = batch[\"image\"].to(device)\n",
    "        y = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(x)\n",
    "        loss = loss_function(outputs, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss_avg = epoch_loss / step\n",
    "    epoch_loss_values.append(epoch_loss_avg)\n",
    "    print(f\"Epoch {global_step} average loss: {epoch_loss_avg:.4f}\\n\")\n",
    "\n",
    "    # ---- VALIDATION ----\n",
    "    if (global_step % eval_num == 0 and global_step != 0) or global_step == max_iterations:\n",
    "        print(f\"Validation at global iteration {global_step}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                val_inputs = batch[\"image\"].to(device)\n",
    "                val_labels = batch[\"label\"].to(device)\n",
    "\n",
    "                with torch.amp.autocast('cuda', enabled=True):\n",
    "                    val_outputs = model(val_inputs)\n",
    "\n",
    "                val_labels_convert = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                val_outputs_convert = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "\n",
    "                dice_metric(y_pred=val_outputs_convert, y=val_labels_convert)\n",
    "\n",
    "        dice_val = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "\n",
    "        metric_values.append(dice_val)\n",
    "        print(f\"Validation Dice: {dice_val:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if dice_val > dice_val_best:\n",
    "            dice_val_best = dice_val\n",
    "            global_step_best = global_step\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(root_dir, f\"best_metric_model_FocalLoss_{current_date}.pth\")\n",
    "            )\n",
    "\n",
    "# ---- SAVE FINAL MODEL ----\n",
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    os.path.join(root_dir, f\"final_model_FocalLoss_{current_date}.pth\"),\n",
    ")\n",
    "\n",
    "# ---- SAVE TRAINING DATA ----\n",
    "json_data = {\n",
    "    \"global_step\": list(range(max_iterations)),\n",
    "    \"loss\": epoch_loss_values,\n",
    "    \"dice_metric\": metric_values,\n",
    "}\n",
    "\n",
    "with open(os.path.join(root_dir, f\"data_FocalLoss_{current_date}.json\"), \"w\") as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "print(f\"Training complete. Best Dice: {dice_val_best:.4f} at iteration {global_step_best}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the learning curves: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load results\n",
    "with open(\"results_data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "loss_values = data[\"loss\"]\n",
    "dice_values = data[\"dice_metric\"]\n",
    "\n",
    "# Plot\n",
    "plt.figure(\"train\", (12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Iteration Average Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(range(len(loss_values)), loss_values, label=\"Training Loss\", marker=\"o\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Validation Mean Dice\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Dice Score\")\n",
    "plt.plot(range(len(dice_values)), dice_values, label=\"Validation Dice\", marker=\"x\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np \n",
    "from monai.transforms import ToTensord, ScaleIntensityd\n",
    "import os\n",
    "import monai\n",
    "\n",
    "test_dir = \"/picai_testset\"\n",
    "test_dataset_json = \"dataset_test.json\"\n",
    "\n",
    "test_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"], image_only=False),\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "    Spacingd(keys=[\"image\", \"label\"],pixdim=(0.5, 0.5, 3.0),mode=(\"bilinear\", \"nearest\"),),\n",
    "    SpatialPadd(keys=[\"image\", \"label\"], spatial_size=(272, 272, 32)), \n",
    "    CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=(272, 272, 32)), \n",
    "    ScaleIntensityRangePercentilesd(keys=[\"image\"], lower=1, upper=99, b_min=0.0, b_max=1.0, clip=True)\n",
    "    ])\n",
    "test_files = load_decathlon_datalist(test_dataset_json, True, \"test\")\n",
    "test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    img_size=(272, 272, 32),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    proj_type=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.3,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from monai.transforms import SaveImaged, AsDiscrete\n",
    "from monai.data import decollate_batch\n",
    "\n",
    "# Create output dirs\n",
    "prediction_dir = \"./prediction\"\n",
    "gt_dir = \"./picai_testset/gt\"\n",
    "os.makedirs(prediction_dir, exist_ok=True)\n",
    "os.makedirs(gt_dir, exist_ok=True)\n",
    "\n",
    "# Post-processing transforms\n",
    "post_label = AsDiscrete()\n",
    "post_pred = AsDiscrete(argmax=True)\n",
    "\n",
    "# Load model\n",
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model_FocalLoss.pth\")))\n",
    "model.eval()\n",
    "\n",
    "# Saving transforms\n",
    "save_pred = SaveImaged(\n",
    "    keys=\"pred\",\n",
    "    output_dir=prediction_dir,\n",
    "    output_postfix=\"pred\",\n",
    "    resample=False,\n",
    "    separate_folder=False,\n",
    "    print_log=False,\n",
    "    meta_key_postfix=\"meta_dict\",\n",
    "    output_ext=\".nii.gz\"\n",
    ")\n",
    "\n",
    "save_gt = SaveImaged(\n",
    "    keys=\"gt\",\n",
    "    output_dir=gt_dir,\n",
    "    output_postfix=\"gt\",\n",
    "    resample=False,\n",
    "    separate_folder=False,\n",
    "    print_log=False,\n",
    "    meta_key_postfix=\"meta_dict\",\n",
    "    output_ext=\".nii.gz\"\n",
    ")\n",
    "\n",
    "# Inference loop\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        labels_post = [post_label(x) for x in decollate_batch(labels)]\n",
    "        preds_post = [post_pred(x) for x in decollate_batch(outputs)]\n",
    "\n",
    "        dice_metric(y_pred=preds_post, y=labels_post)\n",
    "\n",
    "        # Softmax + select positive class\n",
    "        pred_soft = torch.softmax(outputs, dim=1)[:, 1]\n",
    "\n",
    "        # Meta dict reused for pred and gt\n",
    "        meta = {\n",
    "            \"filename_or_obj\": batch[\"label_meta_dict\"][\"filename_or_obj\"][0],\n",
    "            \"affine\": batch[\"label_meta_dict\"][\"affine\"][0],\n",
    "        }\n",
    "\n",
    "        save_pred({\"pred\": pred_soft[0], \"meta_dict\": meta})\n",
    "        save_gt({\"gt\": labels_post[0], \"meta_dict\": meta})\n",
    "\n",
    "    mean_dice = dice_metric.aggregate().item()\n",
    "    dice_metric.reset()\n",
    "\n",
    "print(mean_dice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from picai_eval import evaluate\n",
    "from report_guided_annotation import extract_lesion_candidates\n",
    "import glob\n",
    "\n",
    "pred_cases = sorted(glob.glob(f\"{prediction_dir}/**/*.nii.gz\", recursive=True))\n",
    "gt_cases = sorted(glob.glob(f\"{gt_dir}/**/*.nii.gz\", recursive=True))\n",
    "\n",
    "metrics = evaluate(y_det=pred_cases, y_true=gt_cases, \n",
    "                   y_det_postprocess_func=lambda pred: extract_lesion_candidates(pred, threshold=\"dynamic\")[0],)\n",
    "\n",
    "print(f\"\\n\")\n",
    "print(f\"AUROC: {round(metrics.auroc,4)}\")\n",
    "print(f\"AP: {round(metrics.AP,4)}\")\n",
    "print(f\"PICAI score: {round(.5*(metrics.auroc+metrics.AP),4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
