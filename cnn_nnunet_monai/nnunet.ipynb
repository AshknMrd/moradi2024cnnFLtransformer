{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nnUNet pre-processing:\n",
    "\n",
    "Presprocessing the PI-CAI dataset to implement the centralized + FL experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['nnUNet_raw'] = './workdir/nnUNet_raw'\n",
    "os.environ['nnUNet_preprocessed'] = './workdir/nnUNet_preprocessed'\n",
    "os.environ['nnUNet_results'] = './workdir/nnUNet_results'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting mha to nnUNet structure\n",
    "You can run in the terminal directly or using the Jupyter notebook: \n",
    "\n",
    "```bash\n",
    "python -m picai_prep mha2nnunet_settings \\\n",
    "    --structure picai_archive \\\n",
    "    --input ./input/images/ \\\n",
    "    --annotations ./input/labels/csPCa_lesion_delineations/human_expert/resampled/ \\\n",
    "    --json ./workdir/nnUNet_raw/mha2nnunet_settings.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from picai_prep.examples.mha2nnunet.picai_archive import generate_mha2nnunet_settings\n",
    "\n",
    "generate_mha2nnunet_settings(\n",
    "    archive_dir=\"./input/images/\",\n",
    "    annotations_dir=\"./input/labels_combined\",\n",
    "    output_path=\"./workdir/nnUNet_raw/mha2nnunet_settings.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from picai_prep import MHA2nnUNetConverter\n",
    "\n",
    "archive = MHA2nnUNetConverter(\n",
    "    scans_dir=\"./input/images\",\n",
    "    annotations_dir=\"./input/labels_combined\", \n",
    "    output_dir=\"./workdir/nnUNet_raw\",\n",
    "    mha2nnunet_settings=\"./workdir/nnUNet_raw/mha2nnunet_settings.json\",\n",
    ")\n",
    "archive.convert()\n",
    "archive.create_dataset_json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the labels are binarized, meaning that voxels belonging to the cancerous lesion are represented as 1, and voxels belonging to the background are represented as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "def process_nifti_labels(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if not filename.endswith(\".nii.gz\"):\n",
    "            continue\n",
    "\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        nifti = nib.load(input_path)\n",
    "\n",
    "        data = nifti.get_fdata()\n",
    "        binarized = (data >= 1).astype(np.uint8)\n",
    "\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        nib.save(nib.Nifti1Image(binarized, nifti.affine, nifti.header), output_path)\n",
    "\n",
    "\n",
    "input_folder = \"./workdir/nnUNet_raw/Dataset104_picai/imagesTr\"\n",
    "output_folder = \"./workdir/nnUNet_raw/Dataset104_picai/labelsTr\"\n",
    "\n",
    "process_nifti_labels(input_folder, output_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run nnU-Net Preprocessing\n",
    "\n",
    "Before running preprocessing, make sure that the raw data folders are structured correctly:\n",
    "\n",
    "```\n",
    "workdir/  \n",
    "├── nnUNet_raw/  \n",
    "│   └── Dataset104_picai/  \n",
    "│       ├── imagesTr/  \n",
    "│       ├── labelsTr/  \n",
    "│       └── dataset.json\n",
    "├── nnUNet_preprocessed/  \n",
    "└── nnUNet_results/  \n",
    "```\n",
    "\n",
    "where the `dataset.json` is \n",
    "```json\n",
    "{\n",
    "    \"channel_names\": {\n",
    "        \"0\": \"T2W\",\n",
    "        \"1\": \"ADC\",\n",
    "        \"2\": \"HBV\"\n",
    "    },\n",
    "    \"labels\": {\n",
    "        \"background\": 0,\n",
    "        \"lesion\": 1\n",
    "    },\n",
    "    \"numTraining\": 1500,\n",
    "    \"file_ending\": \".nii.gz\",\n",
    "    \"name\": \"picai_nnunetv2\",\n",
    "    \"reference\": \"none\",\n",
    "    \"release\": \"1.0\",\n",
    "    \"description\": \"bpMRI scans from PI-CAI dataset to train by nnUNetv2\",\n",
    "    \"overwrite_image_reader_writer\": \"SimpleITKIO\"\n",
    "}\n",
    "```\n",
    "\n",
    "Then, run the following command directly in the terminal:\n",
    "\n",
    "```bash\n",
    "nnUNetv2_plan_and_preprocess -d 104 -c 3d_fullres --verify_dataset_integrity\n",
    "```\n",
    "\n",
    "```bash\n",
    "nnUNetv2_train Dataset104_picai 3d_fullres 0 -tr nnUNetTrainerCELoss_1000epochs --npz\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trainig the models for 5 different folds the ensembling model can be computed as:\n",
    "\n",
    "```bash\n",
    "nnUNetv2_find_best_configuration 104 -c 3d_fullres -tr nnUNetTrainerCELoss_1000epochs\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the prediction can be run and the evaluation metrics be computed following the PI-CAI guidelines.\n",
    "\n",
    "```bash\n",
    "nnUNetv2_predict -d Dataset104_picai -i ./imagesTs -o ./workdir/nnUNet_predictions/ -f  0 1 2 3 4 -tr nnUNetTrainerCELoss_1000epochs -c 3d_fullres -p nnUNetPlans\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from picai_eval import evaluate_folder\n",
    "from report_guided_annotation import extract_lesion_candidates\n",
    "\n",
    "pred_softmax = \"./workdir/nnUNet_predictions\"\n",
    "annotations = \"./labelsTs\"\n",
    "metrics = evaluate_folder(y_det_dir=pred_softmax,\n",
    "                          y_true_dir=annotations, \n",
    "                          y_det_postprocess_func=lambda pred: extract_lesion_candidates(pred, threshold=\"dynamic\")[0],)\n",
    "\n",
    "print(f\"\\n\")\n",
    "print(f\"AUROC: {round(metrics.auroc,4)}\")\n",
    "print(f\"AP: {round(metrics.AP,4)}\")\n",
    "print(f\"PICAI score: {round(.5*(metrics.auroc+metrics.AP),4)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
